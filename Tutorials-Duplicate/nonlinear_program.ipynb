{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Nonlinear Program (NLP) Tutorial\nFor instructions on how to run these tutorial notebooks, please see the [index](./index.ipynb).\n\n## Important Note\nPlease refer to the [MathematicalProgram Tutorial](./mathematical_program.ipynb) for constructing and solving a general optimization program in Drake.\n\n## Nonlinear Program\nA Nonlinear Programming (NLP) problem is a special type of optimization problem. The cost and/or constraints in an NLP are nonlinear functions of decision variables. The mathematical formulation of a general NLP is\n\n$\\begin{aligned} \\min_x&\\; f(x)\\\\ \\text{subject to }& g_i(x)\\leq 0 \\end{aligned}$\n\nwhere $f(x)$ is the cost function, and $g_i(x)$ is the i'th constraint.\n\nAn NLP is typically solved through gradient-based optimization (like gradient descent, SQP, interior point methods, etc). These methods rely on the gradient of the cost/constraints $\\partial f/\\partial x, \\partial g_i/\\partial x$. pydrake can compute the gradient of many functions through automatic differentiation, so very often the user doesn't need to manually provide the gradient.\n\n## Setting the objective\nThe user can call `AddCost` function to add a nonlinear cost into the program. Note that the user can call `AddCost` repeatedly, and the program will evaluate the *summation* of each individual cost as the total cost.",
   "metadata": {
    "cell_id": "4d815da4-e325-4ff8-b006-a2ab50858cb1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Adding a cost through a python function\nWe can define a cost through a python function, and then add this python function to the objective through `AddCost` function. When adding a cost, we should provide the variable associated with that cost, the syntax is `AddCost(cost_evaluator, vars=associated_variables)`, which means the cost is evaluated on the `associated_variables`.In the code example below, We first demonstrate how to construct an optimization program with 3 decision variables, then we show how to add a cost through a python function.",
   "metadata": {
    "cell_id": "00001-16f51872-ac7e-4245-8205-76a97a8ba83a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-8800bcaf-db1a-4ffd-ac36-b8b2ae619297",
    "deepnote_cell_type": "code"
   },
   "source": "from pydrake.solvers import MathematicalProgram, Solve\nimport numpy as np\n\n# Create an empty MathematicalProgram named prog (with no decision variables,\n# constraints or costs)\nprog = MathematicalProgram()\n# Add three decision variables x[0], x[1], x[2]\nx = prog.NewContinuousVariables(3, \"x\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-03b2b0a6-69f6-462f-8d07-7f49ba1e9125",
    "deepnote_cell_type": "code"
   },
   "source": "def cost_fun(z):\n    cos_z = np.cos(z[0] + z[1])\n    sin_z = np.sin(z[0] + z[1])\n    return cos_z**2 + cos_z + sin_z\n# Add the cost evaluated with x[0] and x[1].\ncost1 = prog.AddCost(cost_fun, vars=[x[0], x[1]])\nprint(cost1)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Notice that by changing the argument `vars` in `AddCost` function, we can add the cost to a different set of variables. In the code example below, we use the same python function `cost_fun`, but impose this cost on the variable `x[0], x[2]`.",
   "metadata": {
    "cell_id": "00004-d445652c-8ad9-4de9-857a-520cac9a740b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-f1d053a2-ed1f-4c8a-b2cc-428a650ff685",
    "deepnote_cell_type": "code"
   },
   "source": "cost2 = prog.AddCost(cost_fun, vars=[x[0], x[2]])\nprint(cost2)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Adding cost through a lambda function\nA more compact approach to add a cost is through a lambda function. For example, the code below adds a cost $x[1]^2 + x[0]$ to the optimization program.",
   "metadata": {
    "cell_id": "00006-fe745a84-b3a9-4445-9ae8-cd32932b73f9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-a570b4e2-073d-4f16-a6c7-2fd68d977ab9",
    "deepnote_cell_type": "code"
   },
   "source": "# Add a cost x[1]**2 + x[0] using a lambda function.\ncost3 = prog.AddCost(lambda z: z[0]**2 + z[1], vars = [x[1], x[0]])\nprint(cost3)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "If we change the associated variables, then it represents a different cost. For example, we can use the same lambda function, but add the cost $x[1]^2 + x[2]$ to the program by changing the argument to `vars`",
   "metadata": {
    "cell_id": "00008-ca02f72c-6972-4ee8-ad64-af5a787c04b3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-e00b3fe3-a7ec-49be-b42f-aeb175e6fe9f",
    "deepnote_cell_type": "code"
   },
   "source": "cost4 = prog.AddCost(lambda z: z[0]**2 + z[1], vars = x[1:])\nprint(cost4)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Adding quadratic cost\nIn NLP, adding a quadratic cost $0.5x^TQx+ b'x+c$ is very common. pydrake provides multiple functions to add quadratic cost, including\n- `AddQuadraticCost`\n- `AddQuadraticErrorCost`\n- `Add2NormSquaredCost`\n\n### AddQuadraticCost\nWe can add a simple quadratic expression as a cost.",
   "metadata": {
    "cell_id": "00010-d25d419e-356d-421a-8011-08e95952c922",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-d293e89c-26d1-4d24-b09b-6e85ec466ad5",
    "deepnote_cell_type": "code"
   },
   "source": "cost4 = prog.AddQuadraticCost(x[0]**2 + 3 * x[1]**2 + 2*x[0]*x[1] + 2*x[1] * x[0] + 1)\nprint(cost4)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "If the user knows the matrix form of `Q` and `b`, then it is faster to pass in these matrices to `AddQuadraticCost`, instead of using the symbolic quadratic expression as above.",
   "metadata": {
    "cell_id": "00012-30c620ad-b57a-4d7f-a89a-45ef21d32a9d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-53a29f08-3851-4c0d-a7c8-156d61f60eb6",
    "deepnote_cell_type": "code"
   },
   "source": "# Add a cost x[0]**2 + 2*x[1]**2 + x[0]*x[1] + 3*x[1] + 1.\ncost5 = prog.AddQuadraticCost(\n    Q=np.array([[2., 1], [1., 4.]]),\n    b=np.array([0., 3.]),\n    c=1.,\n    vars=x[:2])\nprint(cost5)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### AddQuadraticErrorCost\nThis function adds a cost of the form $(x - x_{des})^TQ(x-x_{des})$.",
   "metadata": {
    "cell_id": "00014-d15e9b12-e324-4e03-98fb-7b0cfac8d514",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00015-35bdea28-ddd0-4583-955d-964341fdd108",
    "deepnote_cell_type": "code"
   },
   "source": "cost6 = prog.AddQuadraticErrorCost(\n    Q=np.array([[1, 0.5], [0.5, 1]]),\n    x_desired=np.array([1., 2.]),\n    vars=x[1:])\nprint(cost6)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Add2NormSquaredCost\nThis function adds a quadratic cost of the form $(Ax-b)^T(Ax-b)$",
   "metadata": {
    "cell_id": "00016-982cfcf6-4e01-4823-aada-ec51c8ebd617",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-6c9f7d4f-35f6-4a7a-9b33-18ea01432cce",
    "deepnote_cell_type": "code"
   },
   "source": "# Add the L2 norm cost on (A*x[:2] - b).dot(A*x[:2]-b)\ncost7 = prog.Add2NormSquaredCost(\n    A=np.array([[1., 2.], [2., 3], [3., 4]]),\n    b=np.array([2, 3, 1.]),\n    vars=x[:2])\nprint(cost7)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Adding constraints\n\nDrake supports adding constraints in the following form\n\\begin{aligned}\nlower \\leq g(x) \\leq upper\n\\end{aligned}\nwhere $g(x)$ returns a numpy vector.\n\nThe user can call `AddConstraint(g, lower, upper, vars=x)` to add the constraint. Here `g` must be a python function (or a lambda function).",
   "metadata": {
    "cell_id": "00018-2d7b19de-854b-4c1b-9c5a-5de5229b5bc7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00019-470e315c-591b-48f8-939e-b1c35424099a",
    "deepnote_cell_type": "code"
   },
   "source": "## Define a python function to add the constraint x[0]**2 + 2x[1]<=1, -0.5<=sin(x[1])<=0.5\ndef constraint_evaluator1(z):\n    return np.array([z[0]**2+2*z[1], np.sin(z[1])])\n\nconstraint1 = prog.AddConstraint(\n    constraint_evaluator1,\n    lb=np.array([-np.inf, -0.5]),\n    ub=np.array([1., 0.5]),\n    vars=x[:2])\nprint(constraint1)\n\n# Add another constraint using lambda function.\nconstraint2 = prog.AddConstraint(\n    lambda z: np.array([z[0]*z[1]]),\n    lb=[0.],\n    ub=[1.],\n    vars=[x[2]])\nprint(constraint2)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Solving the nonlinear program\n\nOnce all the constraints and costs are added to the program, we can call the `Solve` function to solve the program and call `GetSolution` to obtain the results. Solving an NLP requires an initial guess on all the decision variables. If the user doesn't specify an initial guess, we will use a zero vector by default.",
   "metadata": {
    "cell_id": "00020-93b28438-c109-49f4-880b-ba2d60153e81",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00021-1890da51-3a6f-4f3b-adf6-019a72e7cae2",
    "deepnote_cell_type": "code"
   },
   "source": "## Solve a simple nonlinear \n# min               -x0\n# subject to x1 - exp(x0) >= 0\n#            x2 - exp(x1) >= 0\n#            0 <= x0 <= 100\n#            0 <= x1 <= 100\n#            0 <= x2 <= 10\nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(3)\n# The cost is a linear function, so we call AddLinearCost\nprog.AddLinearCost(-x[0])\n# Now add the constraint x1-exp(x0)>=0 and x2-exp(x1)>=0\nprog.AddConstraint(\n    lambda z: np.array([z[1]-np.exp(z[0]), z[2]-np.exp(z[1])]),\n    lb=[0, 0],\n    ub=[np.inf, np.inf],\n    vars=x)\n# Add the bounding box constraint 0<=x0<=100, 0<=x1<=100, 0<=x2<=10\nprog.AddBoundingBoxConstraint(0, 100, x[:2])\nprog.AddBoundingBoxConstraint(0, 10, x[2])\n\n# Now solve the program with initial guess x=[1, 2, 3]\nresult = Solve(prog, np.array([1.,2.,3.]))\nprint(f\"Is optimization successful? {result.is_success()}\")\nprint(f\"Solution to x: {result.GetSolution(x)}\")\nprint(f\"optimal cost: {result.get_optimal_cost()}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Setting the initial guess\nSome NLPs might have many decision variables. In order to set the initial guess for these decision variables, we provide a function `SetInitialGuess` to set the initial guess of a subset of decision variables. For example, in the problem below, we want to find the two closest points $p_1$ and $p_2$, where $p_1$ is on the unit circle, and $p_2$ is on the curve $y=x^2$, we can set the initial guess for these two variables separately by calling `SetInitialGuess`.",
   "metadata": {
    "cell_id": "00022-f2e8d70e-9285-49ed-a5b2-30c23d435762",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00023-2a54cdd6-beb0-4813-bc2e-67ae8e5b2f88",
    "deepnote_cell_type": "code"
   },
   "source": "import matplotlib.pyplot as plt\nprog = MathematicalProgram()\np1 = prog.NewContinuousVariables(2, \"p1\")\np2 = prog.NewContinuousVariables(2, \"p2\")\n\n# Add the constraint that p1 is on the unit circle centered at (0, 2)\nprog.AddConstraint(\n    lambda z: [z[0]**2 + (z[1]-2)**2],\n    lb=np.array([1.]),\n    ub=np.array([1.]),\n    vars=p1)\n\n# Add the constraint that p2 is on the curve y=x*x\nprog.AddConstraint(\n    lambda z: [z[1] - z[0]**2],\n    lb=[0.],\n    ub=[0.],\n    vars=p2)\n\n# Add the cost on the distance between p1 and p2\nprog.AddQuadraticCost((p1-p2).dot(p1-p2))\n\n# Set the value of p1 in initial guess to be [0, 1]\nprog.SetInitialGuess(p1, [0., 1.])\n# Set the value of p2 in initial guess to be [1, 1]\nprog.SetInitialGuess(p2, [1., 1.])\n\n# Now solve the program\nresult = Solve(prog)\nprint(f\"Is optimization successful? {result.is_success()}\")\np1_sol = result.GetSolution(p1)\np2_sol = result.GetSolution(p2)\nprint(f\"solution to p1 {p1_sol}\")\nprint(f\"solution to p2 {p2_sol}\")\nprint(f\"optimal cost {result.get_optimal_cost()}\")\n\n# Plot the solution.\nplt.figure()\nplt.plot(np.cos(np.linspace(0, 2*np.pi, 100)), 2+np.sin(np.linspace(0, 2*np.pi, 100)))\nplt.plot(np.linspace(-2, 2, 100), np.power(np.linspace(-2, 2, 100), 2))\nplt.plot(p1_sol[0], p1_sol[1], '*')\nplt.plot(p2_sol[0], p2_sol[1], '*')\nplt.axis('equal')\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2b4fc509-aef2-417d-a40d-6071dfed9199' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "deepnote_notebook_id": "9ec2412e-87c7-4b73-aeba-471a174f5a9d",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}