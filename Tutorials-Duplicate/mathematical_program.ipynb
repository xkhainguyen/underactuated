{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# MathematicalProgram Tutorial\nFor instructions on how to run these tutorial notebooks, please see the [index](./index.ipynb).\n",
   "metadata": {
    "cell_id": "3e6238c2-cb47-4524-80b1-b0eea1d9d44e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Background\nMany engineering problems can be formulated as mathematical optimization problems, and solved by numerical solvers. A generic mathematical optimization problem can be formulated as\n$\\begin{aligned}\n\\begin{array}{rl}\n                       \\min_x \\;  &  f(x)\n   \\\\\\text{subject to}  \\;  &  x \\in\\mathcal{S}\n   \\end{array}\n   \\qquad\n   \\boxed{\n         \\begin{array}{ll}\n      \\text{The real-valued decision variable is}       &x\\\\\n      \\text{The real-valued cost function is}           &f(x)\\\\\n      \\text{The constraint set is}                      &\\mathcal{S}\\\\\n      \\text{The optimal } x \\text{ that minimizes the cost function is}  &x^*\n      \\end{array}\n      }\n\\end{aligned}$\n\nwhere $x$ is the real-valued decision variable(s), $f(x)$ is the real-valued *cost function*, $\\mathcal{S}$ is the constraint set for $x$. Our goal is to find the optimal $x^*$ within the constraint set $\\mathcal{S}$, such that $x^*$ minimizes the cost function $f(x)$.\n\nFor example, the following optimization problem determines the value of $x$ \nthat minimizes $x^3 + 2x + 1$ subject to $x \\ge 1$.\n$\\begin{aligned}\n\\begin{array}{rl}\n\\min_x\\;&x^3 + 2x + 1\\\\\n\\text{subject to}\\;\\;&x \\ge 1\n\\end{array}\n\\quad\n\\boxed{\n      \\begin{array}{ll}\n          \\text{The real-valued decision variable is}         &  x\\\\\n          \\text{The real-valued cost function }f(x) \\text{ is} &  x^3 + 2x + 1\\\\\n          \\text{The set }\\mathcal{S} \\text{ of constraints is}      &  x \\ge 1\\\\\n          \\text{The value that minimizes the cost function is}    &  x^* = 1\n   \\end{array}\n}\n\\end{aligned}$\n\nIn general, how an optimization problem is solved depends on its categorization (categories include Linear Programming, Quadratic Programming, Mixed-integer Programming, etc.). Categorization depends on properties of both the cost function $f(x)$ and the constraint set $\\mathcal{S}$. For example, if the cost function $f(x)$ is a linear function of $x$, and the constraint $\\mathcal{S}$ is a linear set $\\mathcal{S} = \\{x | Ax\\le b\\}$, then we have a *linear programming* problem, which is efficiently solved with certain solvers. \n\nThere are multiple solvers for each category of optimization problems,\nbut each solver has its own API and data structures.\nFrequently, users need to rewrite code when they switch solvers.\nTo remedy this, Drake provides a common API through the *MathematicalProgram* class.\nIn addition to avoiding solver-specific code,\nthe constraint and cost functions can be written in symbolic form (which makes code more readable).\nIn these ways, Drake's MathematicalProgram is akin to [YALMIP](https://yalmip.github.io/) in MATLAB or [JuMP](https://github.com/JuliaOpt/JuMP.jl) in Julia, and we support both Python and C++.\n<br> Note: Drake supports many [solvers](https://drake.mit.edu/doxygen_cxx/group__solvers.html)\n(some are open-source and some require a license).\n\nDrake can formulate and solve the following categories of optimization problems\n* Linear programming\n* Quadratic programming\n* Second-order cone programming\n* Nonlinear nonconvex programming\n* Semidefinite programming\n* Sum-of-squares programming\n* Mixed-integer programming (mixed-integer linear programming, mixed-integer quadratic programming, mixed-integer second-order cone programming).\n* Linear complementarity problem\n\nThis tutorial provides the basics of Drake's MathematicalProgram.\nAdvanced tutorials are available at the [bottom](#Advanced-tutorials) of this document.\n",
   "metadata": {
    "cell_id": "00001-3c4dd682-af4f-4f94-adaa-dd770b616039",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Basics of MathematicalProgram class\nDrake's MathematicalProgram class contains the mathematical formulation of an optimization problem, namely the decision variables $x$, the cost function $f(x)$, and the constraint set $\\mathcal{S}$.",
   "metadata": {
    "cell_id": "00002-9ebea453-88af-4a3e-b38e-2373b1ae2c69",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Initialize a MathematicalProgram object\n\n To initialize this class, first create an empty MathematicalProgram as",
   "metadata": {
    "cell_id": "00003-f9a4c541-62b8-4eec-aed3-cc7e332de695",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-43af0872-f988-4173-b142-1dd408334256",
    "deepnote_cell_type": "code"
   },
   "source": "from pydrake.solvers import MathematicalProgram\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Create an empty MathematicalProgram named prog (with no decision variables, \n# constraints or cost function)\nprog = MathematicalProgram()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\n\n### Adding decision variables\nShown below, the function `NewContinuousVariables` adds two new continuous decision variables to `prog`.  The newly added variables are returned as `x` in a numpy array. \n<br><font size=-1> Note the range of the variable is a continuous set, as opposed to binary variables which only take discrete value 0 or 1.</font>",
   "metadata": {
    "cell_id": "00005-ea45dbe9-fa4c-4784-b186-1e0a8815f2ad",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-be05d807-4656-4bac-8b38-53955c03539e",
    "deepnote_cell_type": "code"
   },
   "source": "x = prog.NewContinuousVariables(2)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The default names of the variable in *x* are \"x(0)\" and \"x(1)\".  The next line prints the default names and types in `x`, whereas the second line prints the symbolic expression \"1 + 2x[0] + 3x[1] + 4x[1]\".",
   "metadata": {
    "cell_id": "00007-b13d0854-82b2-4be9-9cc3-46b9db918e22",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-44ca8e4b-5570-4757-b24c-cee638654cc3",
    "deepnote_cell_type": "code"
   },
   "source": "print(x)\nprint(1 + 2*x[0] + 3*x[1] + 4*x[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To create an array `y` of two variables named \"dog(0)\"\" and \"dog(1)\", pass the name \"dog\" as a second argument to `NewContinuousVariables()`. Also shown below is the printout of the two variables in `y` and a symbolic expression involving `y`.",
   "metadata": {
    "cell_id": "00009-fecf74bb-26e7-4189-8709-c5052da2c9d2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-f5fc8d92-9259-4c0c-8518-680398b6ef29",
    "deepnote_cell_type": "code"
   },
   "source": "y = prog.NewContinuousVariables(2, \"dog\")\nprint(y)\nprint(y[0] + y[0] + y[1] * y[1] * y[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To create a $3 \\times 2$ matrix of variables named \"A\", type ",
   "metadata": {
    "cell_id": "00011-3c753bea-a96c-4c89-bcd2-4ec3e83a49cc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-28945621-4ce1-45aa-baab-0ee7b09edcf4",
    "deepnote_cell_type": "code"
   },
   "source": "var_matrix = prog.NewContinuousVariables(3, 2, \"A\")\nprint(var_matrix)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Adding constraints\nThere are many ways to impose constraints on the decision variables. This tutorial shows a few simple examples. Refer to the links at the [bottom](#Advanced-tutorials) of this document for other types of constraints.\n\n",
   "metadata": {
    "cell_id": "00013-f3a00bd9-92f8-4e9a-be15-4f2613e52b81",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### AddConstraint\nThe simplest way to add a constraint is with `MathematicalProgram.AddConstraint()`.",
   "metadata": {
    "cell_id": "00014-11671e1b-8b54-41ca-b4f3-a5fdf6db6cb3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00015-f796a0dc-b69f-4ad2-b076-4caba3754066",
    "deepnote_cell_type": "code"
   },
   "source": "# Add the constraint x(0) * x(1) = 1 to prog\nprog.AddConstraint(x[0] * x[1] == 1)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "\nYou can also add inequality constraints to `prog` such as",
   "metadata": {
    "cell_id": "00016-c3ee5de0-e6bf-430b-a9d3-433f0278434d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-51ff617b-c89a-4f94-9c68-9f8e36707a45",
    "deepnote_cell_type": "code"
   },
   "source": "prog.AddConstraint(x[0] >= 0)\nprog.AddConstraint(x[0] - x[1] <= 0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "`prog` automatically analyzes these symbolic inequality constraint expressions and determines they are all *linear* constraints on $x$.",
   "metadata": {
    "cell_id": "00018-6c6231b0-0302-405b-80a9-25a303464f2b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Adding Cost functions\nIn a complicated optimization problem, it is often convenient to write the total cost function $f(x)$ as a sum of individual cost functions\n\n$\\begin{aligned}\nf(x) = \\sum_i g_i(x)\n\\end{aligned}$",
   "metadata": {
    "cell_id": "00019-4d69e054-c955-4fe6-8024-ab0018f3a218",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "\n#### AddCost method.\nThe simplest way to add an individual cost function $g_i(x)$ to the total cost function $f(x)$ is with the `MathematicalProgram.AddCost()` method (as shown below).",
   "metadata": {
    "cell_id": "00020-5444dadc-67a5-49c2-a4fa-d2e38f7a567b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00021-ae6193b9-c1b9-4da2-b117-f3aa7427fc6f",
    "deepnote_cell_type": "code"
   },
   "source": "# Add a cost x(0)**2 + 3 to the total cost. Since prog doesn't have a cost before, now the total cost is x(0)**2 + 3\nprog.AddCost(x[0] ** 2 + 3)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "To add another individual cost function $x(0) + x(1)$ to the total cost function $f(x)$, simply call `AddCost()` again as follows",
   "metadata": {
    "cell_id": "00022-5aa27f50-28f8-445e-875a-76f3a73c05c3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00023-92da5d8d-8897-4631-97e3-48045f6506f9",
    "deepnote_cell_type": "code"
   },
   "source": "prog.AddCost(x[0] + x[1])",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "now the total cost function becomes $x(0)^2 + x(0) + x(1) + 3$.\n\n`prog` can analyze each of these individual cost functions and determine that $x(0) ^ 2 + 3$  is a convex quadratic function, and $x(0) + x(1)$ is a linear function of $x$.",
   "metadata": {
    "cell_id": "00024-7f243124-34d6-4fa9-bc47-4382c8ee6ec5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Solve the optimization problem\nOnce all the decision variables/constraints/costs are added to `prog`, we are ready to solve the optimization problem.\n\n",
   "metadata": {
    "cell_id": "00025-878fac6b-7d0c-442b-ba42-ba8fb65258d7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Automatically choosing a solver\nThe simplest way to solve the optimization problem is to call `Solve()` function. Drake's MathematicalProgram analyzes the type of the constraints/costs, and then calls an appropriate solver for your problem. The result of calling `Solve()` is stored inside the return argument. Here is a code snippet",
   "metadata": {
    "cell_id": "00026-04f91114-8a5e-4885-a89b-63a15e57ef73",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00027-35a79d2b-1710-420a-a960-d722462c5dfa",
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\"\nSolves a simple optimization problem\n       min x(0)^2 + x(1)^2\nsubject to x(0) + x(1) = 1\n           x(0) <= x(1)\n\"\"\"\nfrom pydrake.solvers import Solve\n# Set up the optimization problem.\nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(2)\nprog.AddConstraint(x[0] + x[1] == 1)\nprog.AddConstraint(x[0] <= x[1])\nprog.AddCost(x[0] **2 + x[1] ** 2)\n\n# Now solve the optimization problem.\nresult = Solve(prog)\n\n# print out the result.\nprint(\"Success? \", result.is_success())\n# Print the solution to the decision variables.\nprint('x* = ', result.GetSolution(x))\n# Print the optimal cost.\nprint('optimal cost = ', result.get_optimal_cost())\n# Print the name of the solver that was called.\nprint('solver is: ', result.get_solver_id().name())",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Notice that we can then retrieve optimization result from the return argument of `Solve`. For example, the solution $x^*$ is retrieved from `result.GetSolution()`, and the optimal cost from `result.get_optimal_cost()`.\n\nSome optimization solution is infeasible (doesn't have a solution). For example in the following code example, `result.get_solution_result()` will not report `kSolutionFound`.",
   "metadata": {
    "cell_id": "00028-760d3c87-ea33-4af0-aef2-60bacb7049ff",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00029-e88c1fd7-fdea-4a6c-8da6-842f486659a2",
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\"\nAn infeasible optimization problem.\n\"\"\"\nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(1)[0]\ny = prog.NewContinuousVariables(1)[0]\nprog.AddConstraint(x + y >= 1)\nprog.AddConstraint(x + y <= 0)\nprog.AddCost(x)\n\nresult = Solve(prog)\nprint(\"Success? \", result.is_success())\nprint(result.get_solution_result())",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Manually choosing a solver\n\nIf you want to choose a solver yourself, rather than Drake choosing one for you, you could instantiate a solver explicitly, and call its `Solve` function. There are two apporaches to instantiate a solver. For example, if I want to solve a problem using the open-source solver [IPOPT](https://github.com/coin-or/Ipopt), I can instantiate the solver using either of the two approaches:\n1. The simplest approach is to call `solver = IpoptSolver()`\n2. The second approach is to construct a solver with a given solver ID as `solver = MakeSolver(IpoptSolver().solver_id())`",
   "metadata": {
    "cell_id": "00030-ca614fad-e604-4a7c-9fc0-95b83c78050a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00031-456f8214-9058-4c5b-b915-3f21e526959a",
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\"\nDemo on manually choosing a solver\nSolves the problem\nmin x(0)\ns.t x(0) + x(1) = 1\n    0 <= x(1) <= 1\n\"\"\"\nfrom pydrake.solvers import IpoptSolver\nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(2)\nprog.AddConstraint(x[0] + x[1] == 1)\nprog.AddConstraint(0 <= x[1])\nprog.AddConstraint(x[1] <= 1)\nprog.AddCost(x[0])\n\n# Choose IPOPT as the solver.\n# First instantiate an IPOPT solver.\n\nsolver = IpoptSolver()\n# The initial guess is [1, 1]. The third argument is the options for Ipopt solver,\n# and we set no solver options.\nresult = solver.Solve(prog, np.array([1, 1]), None)\n\nprint(result.get_solution_result())\nprint(\"x* = \", result.GetSolution(x))\nprint(\"Solver is \", result.get_solver_id().name())\nprint(\"Ipopt solver status: \", result.get_solver_details().status,\n      \", meaning \", result.get_solver_details().ConvertStatusToString())\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Note that `solver.Solve()` expects three input arguments, the optimization program `prog`, the initial guess of the decision variable values (`[1, 1]` in this case), and an optional setting for the solver (`None` in this case, we use the default IPOPT setting). If you don't have an initial guess, you could call `solver.Solve(prog)`. Drake will choose a default initial guess (a 0-valued vector), but this initial guess might be a bad starting point for optimization. Note from the following example code, with the default initial guess, the solver cannot find a solution, even though a solution exists (and could be found with initial guess [1, 1]).",
   "metadata": {
    "cell_id": "00032-f582144b-0484-44b4-b28d-9ab12ee86cd2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00033-973875b7-9f58-48ec-88fc-9f1f4ce9d80f",
    "deepnote_cell_type": "code"
   },
   "source": "from pydrake.solvers import MakeSolver\nsolver = MakeSolver(IpoptSolver().solver_id())\nresult = solver.Solve(prog)\nprint(result.get_solution_result())\nprint(\"x* = \", result.GetSolution(x))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Also note that if we know which solver is called, then we can access some solver-specific result, by calling `result.get_solver_details()`. For example, `IpoptSolverDetails` contains a field `status`, namely the status code of the IPOPT solver, we could access this info by",
   "metadata": {
    "cell_id": "00034-71e8feea-713a-44b7-b9a8-45fd2f84c1f9",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00035-10f4c096-a1f7-4fe3-abad-f9523f6f9464",
    "deepnote_cell_type": "code"
   },
   "source": "print(\"Ipopt solver status: \", result.get_solver_details().status,\n      \", meaning \", result.get_solver_details().ConvertStatusToString())",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Each solver has its own details. You should refer to `FooSolverDetails` class on what is stored inside the return argument of `result.get_solver_details()`. For example, if you know that IPOPT is called, then refer to `IpoptSolverDetails` class; for OSQP solver, refer to `OsqpSolverDetails`, etc.\n\n### Using an initial guess\nSome optimization problems, such as nonlinear optimization, require an initial guess. Other types of problems, such as quadratic programming, mixed-integer optimization, etc,  can be solved faster if a good initial guess is provided. The user could provide an initial guess as an input argument in `Solve` function. If no initial guess is provided, Drake will use a zero-valued vector as the initial guess.\n\nIn the example below, we show that an initial guess could affect the result of the problem. Without an user-provided initial guess, the solver might be unable to find the solution.",
   "metadata": {
    "cell_id": "00036-2fa91821-5de5-43dc-a2b7-6973f9d76241",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00037-582362a7-70a1-4bf6-bf64-4f3eed15d2a6",
    "deepnote_cell_type": "code"
   },
   "source": "from pydrake.solvers import IpoptSolver\nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(2)\nprog.AddConstraint(x[0]**2 + x[1]**2 == 100.)\nprog.AddCost(x[0]**2-x[1]**2)\nsolver = IpoptSolver()\n# The user doesn't provide an initial guess.\nresult = solver.Solve(prog, None, None)\nprint(f\"Without a good initial guess, the result is {result.is_success()}\")\nprint(f\"solution {result.GetSolution(x)}\")\n# Pass an initial guess\nresult = solver.Solve(prog, [-5., 0.], None)\nprint(f\"With a good initial guess, the result is {result.is_success()}\")\nprint(f\"solution {result.GetSolution(x)}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "For more details on setting the initial guess, the user could refer to [Nonlinear program](./nonlinear_program.ipynb) section `Setting the initial guess`.\n\n\n## Add callback\nSome solvers support adding a callback function in each iteration. One usage of the callback is to visualize the solver progress in the current iteration. `MathematicalProgram` supports this usage through the function `AddVisualizationCallback`, although the usage is not limited to just visualization, the callback function can do anything. Here is an example",
   "metadata": {
    "cell_id": "00038-ead3816f-3f70-42e8-b2d9-231f0118d3d6",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00039-4480518c-f427-4822-b9ab-286ed8e10dce",
    "deepnote_cell_type": "code"
   },
   "source": "# Visualize the solver progress in each iteration through a callback\n# Find the closest point on a curve to a desired point.\n\nfig = plt.figure()\ncurve_x = np.linspace(1, 10, 100)\nax = plt.gca()\nax.plot(curve_x, 9./curve_x)\nax.plot(-curve_x, -9./curve_x)\nax.plot(0, 0, 'o')\nx_init = [4., 5.]\nax.plot(x_init[0], x_init[1], 'x', color='red')\n\ndef update(x):\n    ax.plot(x[0], x[1], 'x', color='red')\n    \nprog = MathematicalProgram()\nx = prog.NewContinuousVariables(2)\nprog.AddConstraint(x[0] * x[1] == 9)\nprog.AddCost(x[0]**2 + x[1]**2)\nprog.AddVisualizationCallback(update, x)\nresult = Solve(prog, x_init)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Advanced tutorials\n[Setting solver parameters](./solver_parameters.ipynb)\n\n[Updating costs and constraints (e.g. for efficient solving of many similar programs)](./updating_costs_and_constraints.ipynb)\n\n[Debugging tips](./debug_mathematical_program.ipynb)\n\n[Linear program](./linear_program.ipynb)\n\n[Quadratic program](./quadratic_program.ipynb)\n\n[Nonlinear program](./nonlinear_program.ipynb)\n\n[Sum-of-squares optimization](./sum_of_squares_optimization.ipynb)",
   "metadata": {
    "cell_id": "00040-90bf0027-b0e5-4764-b021-4e206526bebe",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2b4fc509-aef2-417d-a40d-6071dfed9199' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 1,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "deepnote_notebook_id": "91635269-f7b5-44fc-80e7-27e5d4d09dd7",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}