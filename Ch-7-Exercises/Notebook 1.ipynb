{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"6c63aaba58f2498da3201eb6923e44e6","deepnote_cell_type":"markdown","tags":[]},"source":["### Exercise 7.1 \n","Show that any solution, where is any constant scalar, is a fixed point of this value iteration update.\n","*Substitue $\\hat{J}^* = J^* + c$ into Bellman eqn at fixed point ($\\ell = 0,\\: f(s_i,\\pi ^*(s_i))=s_i$), because $c$ is constant scalar then pull it out of min operator, the eqn is always true.*\n","\n","Is the controller still optimal, even if the estimated cost-to-go function is off by a constant factor?\n","*Yes. The controller only depends on the gradient of J.*\n","\n","Is still a fixed point of the value iteration update when discounted?\n","*No. Substitue $\\hat{J}^* = J^* + c$ into Bellman eqn at fixed point ($\\ell = 0,\\: f(s_i,\\pi ^*(s_i))=s_i$), because of $\\gamma (J^*+c)$, so the eqn is not always true.*\n","*However, I'm still concerned that even $\\hat{J}^* = J^*$ is not a fixed point as well in this case.*\n","### Exercise 7.2 (Choosing a Cost Function)\n","a. $\\mathbf{Q} = \\text{diag}([0,1,0]), \\: R = 0$\n","(Maybe we should consider $\\theta$ as well)\n","b. More aggressive control\n","\n","c. $\\mathbf{Q}[3,3]$ and $R$ (one index rule)\n","\n","d. Yes and No. \n","We can set off-diagonal entries of $\\mathbf{Q}$ to capture the coupled state effects, $\\mathbf{Q}[2,3]$ in this case.\n","But sharp turns can depend on $u$ as well. Thinking of this as LQR where $u = -\\mathbf{k}\\mathbf{x}$. Then I guess we should include $yHu$ in the objective function.\n","\n","e. No. Because I don't want to restrict $x$ to be zero. $\\mathbf{Q}[1,1]$ should always = 0.\n","\n","### Exercise 7.4 (A Linear System with Quadratic Cost)\n","a. Yes. It is quadratic so it cannot be negative. If it is zero then we are already at the goal.\n","\n","b. $S=K=3$\n","\n","c. $J^*$ must be in quadratic form. Option iii includes constant 3 (which feels right!). Otherwise, we could solve the discrete-time HJB eqn.\n","\n","### Exercise 7.5 (Value Iteration for Minimum-Time Problems)\n","In this exercise we analyze the performance of the value-iteration algorithm, considering its application to the minimum time problem for the double integrator. In this python notebook, you will find everything you need for this analysis. Take the time to go through the notebook and understand the code in it, then answer the following questions.\n","\n","a. At the end of the notebook section \"Performance of the Value-Iteration Policy\", we plot the state trajectory of the double integrator in closed loop with the value-iteration policy, as well as the resulting control signal.\n","\n","i. Does the state-space trajectory follow the theoretically-optimal quadratic arcs we have seen in the example?\n","*Quite similar but not identical*\n","\n","ii. Is the control policy we get from value iteration a bang-bang policy?\n","*No*\n","\n","iii. Explain in a couple of sentences, what is the reason for this behavior.\n","*All of these are due to discretization errors. It is not a bang-bang policy and has spikes due to interpolation (interpolated input cannot be max or min) at this wide boundary.*\n","\n","b. n the \"Value Iteration Algorithm\" section of the notebook, increase the number of knot points to refine the state-space mesh used in the value iteration. Does this fix the issues you have seen in point (a)?\n","*Finer state-space discretization does not help.*\n","\n","c. In the final section of the notebook, implement the theoretically-optimal control policy from the example, and use the plots to verify that the closed-loop system behaves as expected.\n","*Check my code. The closed-loop system behaves as expected.*\n","\n","### Exercise 7.6 (Linear Program for Dynamic Programming)\n","In this exercise we solve the dynamic programming using a linear program, considering its application to the grid world. In this python notebook, you will write a linear program for solving the optimal cost-to-go in the grid world.\n","*Check my code.*"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8f64d9d4-3a21-4e27-9041-6dcaf956f486' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"88b3c70e1ce44c2b850c36bbc0098c49","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
